{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-21700741e3bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Need Custom imports of dataload, training, validation, model selection, logger, prediction, data augmentation, loss, sampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneuro\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNet\u001b[0m \u001b[0;31m# Baseline model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Importing Utilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "# Need Custom imports of dataload, training, validation, model selection, logger, prediction, data augmentation, loss, sampler\n",
    "from src.neuro import Net # Baseline model\n",
    "\n",
    "\n",
    "# Importing Utilities\n",
    "import random\n",
    "import logging\n",
    "import time\n",
    "from timeit import default_timer as timer\n",
    "import os\n",
    "\n",
    "# Libraries\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F # Transform params\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch.utils.data.sampler import WeightedRandomSampler, SubsetRandomSampler\n",
    "########################################################\n",
    "mode = Net(4).cuda()\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 352\n",
    "\n",
    "# Normalization param\n",
    "# normalize = transforms.Normalize(mean=[x,x,x],\n",
    "                                #     std=[x,x,x])\n",
    "    \n",
    "# Optimizer param\n",
    "optimizer = optim.SGD(model.parameters(),lr=1e-3, momentum=0.9, weight_decay=0.0005) # Fine tune these\n",
    "\n",
    "# criterion = ConvolutedLoss()\n",
    "# Need to figure this parameter out\n",
    "# .cuda() at end\n",
    "\n",
    "# These are also binary labels, no weight\n",
    "classes = [1, 2, 3, 4]\n",
    "\n",
    "save_dir = './snapshots'\n",
    "\n",
    "#########################################################\n",
    "## Loading the dataset\n",
    "\n",
    "## Augmentation + Normalization for full training\n",
    "ds_transform_augmented = transforms.Compose([\n",
    "                 transforms.RandomSizedCrop(224),\n",
    "                 PowerPIL(),\n",
    "                 transforms.ToTensor(),\n",
    "                 # normalize\n",
    "])\n",
    "\n",
    "## Normalization only for validation and test though\n",
    "ds_transform_raw = transforms.Compose([\n",
    "                 transforms.Scale(224),\n",
    "                 transforms.ToTensor(),\n",
    "                 # normalize\n",
    "                 ])\n",
    "##########################################################\n",
    "## Train and Validation\n",
    "X_train = DiabRetinopathyDataset('./Datasets/trainLabels.csv','./data/train/','.jpg',\n",
    "                                 ds_transform_augmented\n",
    "                                 )\n",
    "X_val = DiabRetinopathyDataset('./Datasets/trainLabels.csv','.data/train/','.jpg',\n",
    "                               ds_transform_raw\n",
    "                               )\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetSampler(valid_idx)\n",
    "\n",
    "##########################################################\n",
    "## Both dataloader loads from the same dataset but with different indices\n",
    "train_loader = DataLoader(X_train,\n",
    "                          batch_size=batch_size,\n",
    "                          sampler=train_sampler,\n",
    "                          num_workers=4,\n",
    "                          pin_memory=True)\n",
    "\n",
    "valid_loader = DataLoader(X_val,\n",
    "                          batch_size=batch_size,\n",
    "                          sampler=valid_sampler,\n",
    "                          num_workers=4,\n",
    "                          pin_memory=True)\n",
    "\n",
    "##########################################################\n",
    "## Start training\n",
    "best_score = 0\n",
    "for epoch in range(epochs):\n",
    "    epoch_timer = timer()\n",
    "    \n",
    "    # Train and validate\n",
    "    train(epoch, train_loader, model, criterion, optimizer)\n",
    "    score, loss, threshold = validate(epoch, valid_loader, model, criterion, X_train.getLabelEncoder())\n",
    "    # Save scores\n",
    "    is_best = score > best_score\n",
    "    best_score = max(score, best_score)\n",
    "    snapshot(save_dir, run_name, is_best,{\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': best_score,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'threshold': threshold,\n",
    "        'val_loss': loss\n",
    "    })\n",
    "    \n",
    "    end_epoch_timer = timer()\n",
    "    logger.info(\"#### End epoch{}, elapsed time: {}\".format(epoch, end_epoch_timer - epoch_timer))\n",
    "\n",
    "###########################################################\n",
    "## Prediction\n",
    "X_test = DiabRetinopathyDataset('./Dataset/sampleSubmission.csv','./data/test/','.jpg',\n",
    "                                 ds_transform_raw\n",
    "                                )\n",
    "test_loader = DataLoader(X_test,\n",
    "                         batch_size=batch_size,\n",
    "                         num_workers=4,\n",
    "                         pin_memory=True)\n",
    "\n",
    "# Load model from best iteration\n",
    "# logger.info('----Loading best model for prediction')\n",
    "checkpoint = torch.load(os.path.join(save_dir,\n",
    "                                     run_name + '-model_best.pth'\n",
    "                                     )\n",
    "                       )\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "# Predict\n",
    "predictions = predict(test_loader, model) # TODO Set up module\n",
    "\n",
    "output(predictions,\n",
    "       checkpoint['threshold'],\n",
    "       X_test,\n",
    "       X_train.getLabelEncoder(),\n",
    "       './out',\n",
    "       run_name,\n",
    "       checkpoint['best_score'])\n",
    "\n",
    "###########################################################\n",
    "\n",
    "end_global_timer = timer()\n",
    "logger.info(\"------------------Success-----------------\")\n",
    "logger.info(\"Total elapsed time: %s\" % (end_global_timer - global_timer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
